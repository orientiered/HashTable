# Hash table / хэш-таблица

English version (may be outdated): [README_en.md](README_en.md)

Ассоциативный массив на основе [хэш-таблицы](https://ru.wikipedia.org/wiki/Хеш-таблица) со строками в качестве ключей.

Проект является лабораторной работой по оптимизации хэш-таблицы для x86_64 с использованием различных способов: написание функций на [ассемблере](source/crc32.s), использование inline ассемблера и интринсиков. 

## Что оптимизируем?

Сценарий использования хэш-таблицы является определяющим фактором для направления оптимизаций. Иногда необходимо быстро добавлять и удалять элементы, иногда искать, а может и всё сразу.

В данной работе было принято решение оптимизировать функцию поиска элемента в таблице по его ключу. При этом операция добавления элемента также заметно ускорится, ведь одна из её частей - проверка на то, что элемента нет в таблице, т.е. его поиск.  

Сценарий использования будет следующим: посчитать частоты только тех слов из файла 2, которые есть в файле 1. Предполагается, что файл 1 много меньше файла 2. Кроме того предлолагается, что большинство слов короткие (меньше 16 символов), что близко к правде для человеских языков (по разным [источникам](https://qna.habr.com/q/554389) в русском языке средняя длина слова порядка 6.5 букв, в английском 5.5 букв).

## Компиляция

```bash
    git clone -b v2 https://github.com/orientiered/HashTable.git
    cd HashTable
    make BUILD=RELEASE
```

Для генерации конфига `clangd`, используйте `make compile_commands`.

## Хэш-функции

Есть несколько встроенных хэш-функций (все они написаны для работы с C-строками):

+ `checksum` - сумма ascii кодов букв строки
+ `djb2` - простой и достаточно быстрый алгоритм хеширования
+ `crc32` - очень популярный алгоритм хеширования, за основу взята версия с таблицей предпосчитанных значений

Теоретически можно использовать свою хэш-функцию, указав её в `include/hashTable.h` в `#define _HASH_FUNC`.

При этом она должна иметь следующий вид:

+ `hash_t your_hash(const void *ptr);`
+ `ptr` - указатель на начало C-строки

### Анализ распределения хэш-функций

Для эффективной работы таблицы элементы дожны быть равномерно распределены по бакетам. Для оценки распределения есть функция `hashTableCalcDistribution`, которая считает дисперсию количества элементов в бакетах и строит в консоли график.

TODO: добавить тесты других хэш-функций и графики

+ crc32: дисперсия 4.03

## Как тестируем

Машина: Lenovo XiaoXin X16 Pro (2024)

CPU: AMD Ryzen 7 8845H w/ Radeon 780M Graphics 3.80 GHz (8 cores, 16 threads)

Компилятор: g++ 13.3.0

OS: Linux Mint 22.1 x86_64

### Тестовые файлы

Указанные в сценарии использования файлы 1 и 2 будут сгенерированы из [полного собрания сочинений Шекспира](https://www.gutenberg.org/cache/epub/100/pg100.txt). [Файл](shakespeare.txt)

1.`testString.txt`: текст разделяется на слова, всё остальное убирается. Слова расположены по одному на строке.

2.`testRequests.txt`: набор из 10 миллионов слов (порядка 50МБ), 90% взяты из `testString.txt`, остальные сгенерированы рандомно с длиной от 3 до 14 символов.

Файл 2 обрабатывается `TEST_LOOPS` раз, по умолчанию 10.

Эти файлы генерируются при помощи команды `make test_file`. Можно поменять количество тестов при помощи `TESTS`(10 миллионов по умолчанию) и часть слов, взятых из файла 1 - `FOUND_PERCENT` (0.9 по умолчанию).

### Измерение времени

Для измерения времени использовались ~~14 индусов с секундомерами~~ `clock_gettime` в режиме `CLOCK_PROCESS_CPUTIME_ID` и `_rdtsc`. `_rdtsc` возвращает текущее количество тактов процессора, обладает большей точностью и меньшими накладными расходами, но поскольку время теста порядка 5-10 секунд, особо смысла в ней нет: гораздо большую погрешность вносит операционная система.

Поскольку оптимизируется функция поиска, то наибольший интерес представляет время, проведенное в цикле подсчёта слов из файла 2. Время, затраченное на подготовку данных и загрузку слов из файла 1 в таблицу, не учитывается, так как это уже совсем другая задача.

### О погрешностях

Для оценки погрешности будем запускать тест 6 раз подряд. 
Первый результат отбрасывается, от остальных пяти берётся среднее, в качестве погрешности берём среднеквадратичное отклонение:

```math
    \sigma_t = \sqrt{\frac{N}{N-1}} * \sqrt{\overline{t^2} - \overline{t}^2 }
```

(первый множитель - поправка, связанная с малым количеством измерений)

### Запуск теста

`make run`.

Программа пересобирается в релизную версию и запускается на 1 ядре при помощи команды `taskset 0x1`.

### Троттлинг

Его нет. Тест достаточно короткий (около 10 секунд), поэтому процессор не успевает нагреться выше 60 градусов.

### Важно: Load factor

Load factor - среднее количество элементов в бакете таблицы. Оптимальным значением является 0.75 - 1.5 (в java 0.75, в C# 1.0), но в учебных целях таблица строится с заведомо большим коэффициентом "заполненности": 15-17. Это сделано для того, чтобы было проще увидеть части, которые занимают много времени при исполнении. В конце будет проведено сравнение с правильной "настройкой" хэш-таблицы.

## Оптимизации

Структура первой версии:

+ Память для ключей и значений выделяется при помощи `calloc` (простая наивная реализация)
+ В бакетах элементы хранятся в виде списка (**не массив**), ноды выделяются при помощи `calloc`
+ О длинах строк ничего не известно

### Тесты первой версии

(Odefault - компиляция без ключей оптимизации)

| Версия   | Время, с       | Время одного запроса, тактов |
|-------   |----            |-----                         |
| Odefault | 16.7  +- 0.1   | 634 +- 4                     |
| -O3      | 14.9  +- 0.1   | 566 +- 4                     |

Для профилирования программы будем использовать утилиту `perf` и программу `hotspot` для анализа полученного профиля.

Иногда будут встречаться т.н. `flamegraph`ы - визуализация стека вызовов, отражающая время исполнения каждой функции.

Для запуска профилирования есть команда `make perfTest` - она компилирует релизную версию с флагом `-fno-omit-frame-pointer`, который делает обязательным сохранение rbp в функциях (без этого perf может неправильно интерпретировать stack trace и пропускать названия функций). 

Затем запускает профилирование c флагами `-g` (записать трейс стека) и `--call-graph dwarf`. Частота выборок по умолчанию 10000 Гц, но её можно поменять при помощи опции `FREQ`. **Примечение**: реальная частота снэпшотов perf может отличаться.

#### Профиль 1

При помощи `hotspot` рассмотрим наиболее горячие функции.

![no_opt](docs/hotspot_0.png)
(реальная частота 7.585KHz)

Отсортируем их по собственному времени. Видно, что наиболее ресурсоёмкой оказалась функция сравнения строк, а точнее `__strcmp_evex` - уже оптимизированная под AVX512 функция сравнения строк. Следующие кандидаты - функция поиска в списке и подсчёт хеша.

### Оптимизация strcmp

Как мы выяснили раньше, первым кандидатом на оптимизацию является `strcmp`. Несмотря на то, что библиотечная версия уже оптимизирована с применением SIMD, она ничего не знает о выравнивании и длине строк. Поэтому можно хранить ключи в таблице с выравниванием `KEY_ALIGNMENT`, и, возможно, длину ключей. Перейдём непосредственно к реализации.

+ `aligned_alloc` вместо `calloc` создаст необходимое выравнивание для строк, чтобы их можно было быстро загрузить в SIMD регистр.
+ Байты после конца строки нулевые до конца выравненного блока. Это позволит не беспокоиться о том, что в SIMD регистр попадёт часть другой строки или вообще чужая память.
+ Если известна длина строки, то логично сначала сравнить её. Несмотря на то, что это алгоритмическая оптимизация, не добавлять её довольно глупо. Она может быть включена при помощи `#define CMP_LEN_FIRST`.
+ Оптимизированный `fastStrcmp`:

    ```c
    typedef __m128i MMi_t;
    #define _MM_LOAD(ptr) _mm_load_si128(ptr)
    #define _MM_CMP_MOVEMASK(a, b) _mm_movemask_epi8(_mm_cmpeq_epi8(a, b))
    static const uint32_t _MM_MASK_CONSTANT = 0xFFFF;

    static int fastStrcmp(MMi_t a, MMi_t *bptr) {
        MMi_t b = _MM_LOAD(bptr);
        //k-th bit of cmpMask = (a[k] == b[k])
        uint32_t cmpMask = (uint32_t) _MM_CMP_MOVEMASK(a, b); 
        //_MM_MASK_CONSTANT is 0xFFFF for SSE and 0xFFFFFFFFF for AVX2
        return (int) (cmpMask ^ _MM_MASK_CONSTANT); 
    }
    ```

    В SSE4.2 есть специализированные инструкции для сравнения строк, но у них [задержка](https://www.laruence.com/sse/) минимум в 10 тактов, в то время как комбинация `cmpeq` и `movemask` требует суммарно 3 такта.

    Кроме того, эта функция предполагает, что ключ был загружен в SIMD регистр. Посмотрим, как это делается:

    ```c
    /// Part of the bucketSearch function
    keyLen = strlen(key);

    if (keyLen >= SMALL_STR_LEN) {
        // Key doesn't fit in SIMD register
        while (node) {
            if (CMP_LEN_OPT(node->len == keyLen &&) strcmp(node->key, key) == 0 )
                return node;

            node = node->next;
        }

    } else {
        // Creating local aligned array of chars for key
        alignas(KEY_ALIGNMENT) char keyCopy[SMALL_STR_LEN] = "";
        // Copying key to it
        memcpy(keyCopy, key, keyLen+1);
        // Loading key to SIMD register
        MMi_t searchKey = _MM_LOAD((MMi_t *) keyCopy);

        while (node) {
            //! Alignment of node->key is guaranteed by aligned_calloc with KEY_ALIGNMENT
            if (CMP_LEN_OPT(node->len == keyLen &&) fastStrcmp(searchKey, (MMi_t *) node->key) == 0)
                return node;

            node = node->next;

        }
    }
    ```

    `CMP_LEN_OPT(...)` раскрывается в свои аргументы, если есть `#define CMP_LEN_FIRST`. Так можно отключить эту оптимизацию и убрать одно из полей в структуре ноды.

    Использование `memcpy`, даже несмотря на то, что компилятор инлайнит эту функцию, может быть довольно медленным. Возможно лучшим решением будет невыровненная загрузка 16 байт в `xmm` регистр и маскирование лишних байт после конца строки. Проверим эту теорию позже.

#### Результаты тестирования

| `FAST_STRCMP` | `CMP_LEN_FIRST` | Время, с | Тактов |
|---------------|-----------------|----------|--------|
| Да | Нет | 12.40 +- 0.04 | 470 +- 2 |
| Нет | Да | 13.18 +- 0.06 | 500 +- 2 |
| Да | Да | 12.43 +- 0.06 | 471 +- 2 |

Время работы уменьшилось в 1.2 раза. При этом предварительное сравнение длин строк не улучшило результат.

Проведём профилирование, отключив предварительное сравнение длин строк:

![strcmp_opt](docs/hotspot_1.png)

Теперь сравнение строк суммарно занимает порядка 35% - заметное улучшение.

Попробуем описанный ранее альтернативный метод загрузки ключа в регистр:

``` c
// 16 FF and 16 00
const uint8_t mask[32] = 
{255, 255, 255, 255, 255, 255, 255, 255, 
    255, 255, 255, 255, 255, 255, 255, 255};

MMi_t searchKey = _mm_loadu_si128((const __m128i_u *) key);
MMi_t maskReg   = _mm_loadu_si128((const __m128i_u *) (mask + (16 - keyLen)) );
searchKey = _mm_and_si128(searchKey, maskReg);
```

Проведём тестирование:

+ Время: 12.45 +- 0.04
+ Такты: 472   +- 1.3

Улучшения нет. Пока вернёмся к предыдущему подходу.

### Crc32 written in asm

`CRC32` takes almost 15% of computing time. This hashing algorithm is so widely used, that CPU's have dedicated instruction to calculate it: `crc32`.

```asm
;========================================================
; Crc32 hashing algorithm for C strings
; Args:
;   rdi - memory address
; Ret:
;   rax - crc32 hash
;========================================================
fastCrc32u:
    xor  rax, rax
    dec  rax        ; rax = all ones
    .hash_loop:
        mov   sil, BYTE [rdi]
        inc   rdi
        crc32 rax, sil
        test  sil, sil
        jnz   .hash_loop

    ret
```

Execution time: 9.2 seconds, 34.9 * 10^9 clock cycles

![crc32u_hotspot](docs/hotspot_crc32u.png)

![crc32u_flame](docs/flame_crc32u.png)

Program now works faster, but hashing function takes more cycles. Probable explanation: `crc32` uses different polynom, which has better distribution. On my test file dispersion of elements in bucket decreased from 4.03 to 3.93.
