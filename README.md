# Hash table / Хеш-таблица

English version (outdated): [README_en.md](README_en.md)

Ассоциативный массив на основе [хеш-таблицы](https://ru.wikipedia.org/wiki/Хеш-таблица) со строками в качестве ключей.

Проект является лабораторной работой по оптимизации хеш-таблицы со способом разрешения коллизий методом цепочек  для x86_64 с использованием различных аппаратно-зависимых оптимизаций: написание функций на [ассемблере](source/crc32.s) и использование inline ассемблера для оптимизации функции хеширования, интринсиков для ускорения функции сравнения строк, а также изменение метода хранения данных для лучшего использования кеша. Также проверяется влияние выравнивания на скорость работы программы.

В результате время 100 млн поисков удалось уменьшить с 16.7 +- 0.1 секунд до 2.195+-0.005 секунд. (Ускорение в 7.6+-0.1 раз).

## Немного теории

Некоторая информация этого раздела была взята из статьи ["Пишем обобщённую хеш-таблицу с открытой адресацией на чистом C"](https://habr.com/ru/articles/704724/).

**Хеш-таблица** - один из способов реализации **ассоциативного массива**, который позволяет получить элемент по его ключу. В роли ключа часто выступают строки. В хеш-таблице соответствие между ключом и местом в массиве данных устанавливается хэш-функцией. Уникальных хешей слишком много (обычно больше 2^32), чтобы установить биекцию между элементами массива и множеством хешей. Кроме того, разным данным может соответствовать одинаковый хеш. Поэтому могут возникать **коллизии** - сопоставление разным ключам одного места в таблице.

Существует множество **алгоритмов разрешения коллизий**. Наиболее популярные - **метод цепочек/списков** и **открытая адресация**.

1. **Метод цепочек**

    Хеш-таблица представляет собой массив бакетов (корзин). Между множеством хешей и индексами этого массива устанавливается инъекция, например, при помощи взятия остатка по модулю размера массива. Размер массива иногда делают равным степени двойки (для ускорения операции деления), либо простым числом. Каждый бакет - список из пар ключ-значение. Все операции с таблицей проходят по следующей схеме:

    1) Расчёт хеша данного ключа
    2) Вычисление индекса в массиве бакетов
    3) Поиск/удаление/добавление элемента в списке

    ![Хеш-таблица, построенная на списках](docs/hashTable_list.svg "Пример поиска слова в хеш-таблице на списках")

    На рисунке показан пример поиска слова в таблице. В одном списке лежат элементы, у которых совпал хеш по модулю размера массива. Значения не показаны для простоты.

2. **Открытая адресация**

    В этом случае хеш-таблица - циклический массив пар ключ-значение. Аналогично предыдущему способу для данного ключа находится индекс в этом массиве, а затем начинается **пробирование** - поиск по определённому алгоритму нужного элемента в массиве/места для вставки нового. В случае вставки элемент ставится на первое найденное свободное место.

    Эмпирически было установлено, что хорошим алгоритмом пробирования является **квадратичное пробирование**. В отличие от линейного поиска с шагом 1, в квадратичном пробировании шаг - арифметическая прогрессия: 1, 2, 3, ...

    Алгоритм:
    1) Расчёт хеша данного ключа
    2) Вычисление индекса в циклическом массиве элементов
    3) Поиск/удаление/добавление элемента в массиве при помощи пробирования

    ![Визуализация квадратичного пробирования](docs/hashTable_open_addr.svg "Квадратичное пробирование для поиска слова в таблице с открытой адресацией")

    На рисунке показано, как мог выглядеть массив и поиск в нём. Стоит помнить, что остальные ключи лежат в этом же массиве и пути пробирования для разных начальных индексов могут пересекаться.

    Главный плюс этого метода - хорошая локальность, благодаря которой данные лучше ложатся на кеш процессора. Из минусов - он требует больше памяти, так как заполнение массива более чем на 75% (характерное значение) сильно увеличивает число коллизий, тем самым замедляя работу программы.

## Что оптимизируем?

Сценарий использования хеш-таблицы является определяющим фактором для направления оптимизаций. Иногда необходимо быстро добавлять и удалять элементы, иногда искать, а может и всё сразу.

В данной работе было принято решение оптимизировать функцию поиска элемента в таблице по его ключу. При этом операция добавления элемента также заметно ускорится, ведь одна из её частей - проверка на то, что элемента нет в таблице, т.е. его поиск.  

**Примечание**: на данный момент операция удаления не поддерживается

Сценарий использования будет следующим: посчитать частоты только тех слов из файла 2, которые есть в файле 1. Предполагается, что файл 1 много меньше файла 2. Из этого следует, что число операций вставки на несколько порядков меньше числа операций поиска. Кроме того предлолагается, что большинство слов короткие (меньше 16 символов), что близко к правде для человеческих языков (по разным [источникам](https://qna.habr.com/q/554389) в русском языке средняя длина слова порядка 6.5 букв, в английском 5.5 букв).

## Компиляция

```bash
    git clone -b new_arch https://github.com/orientiered/HashTable.git
    cd HashTable
    make BUILD=RELEASE
```

Для генерации конфига `clangd`, используйте `make compile_commands`.

## Хеш-функции

В  комплекте с хеш-таблицей идёт несколько хеш-функций (все они написаны для работы с C-строками):

+ `checksum` - сумма ascii кодов букв строки
+ `djb2` - простой и достаточно быстрый алгоритм хеширования
+ `crc32` - очень популярный алгоритм хеширования, за основу взята версия с таблицей предподсчитанных значений

Теоретически можно использовать свою хеш-функцию, указав её в `include/hashTable.h` в `#define _HASH_FUNC`.

При этом она должна иметь следующий вид:

+ `hash_t your_hash(const void *ptr);`
+ `ptr` - указатель на начало C-строки

### Анализ распределения хеш-функций

Для эффективной работы таблицы элементы должны быть равномерно распределены по бакетам. Для оценки распределения есть функция `hashTableCalcDistribution`, которая считает дисперсию количества элементов в бакетах и строит в консоли график распределения размера бакета по номеру бакета.

| хеш   | Дисперсия |
|-------|-----------|
| checksum  | 24.58 |
| djb2  | 8.98      |
| crc32 | 4.03      |

Посмотрим на гистограмму распределения размера по количеству бакетов с таким размером:

| Checksum | Djb2 |
|----------|------|
|![checksum hist](docs/checksum_dist.png) | ![djb2_hist](docs/djb2_dist.png) |

![crc32_hist](docs/crc32_dist.png)

Если хеш-функция действительно случайна (здесь за случайную величину принимаем индикатор того, что элемент попал в бакет с фиксированным номером), то, согласно центральной предельной теореме, сумма большого числа таких событий (= размер бакета) будет стремиться к нормальному распределению.

Гистограмма `checksum` представляет собой непонятно что, `djb2` выглядит немного похожим на Гауссово распределение, но всё ещё далёк от него.

Гистограмма `crc32` довольна близка к нормальному распределению, причём её максимум (16) совпадает с мат. ожиданием (16.4). Её дисперсия известна, поэтому можно сделать оценку: 67% бакетов имеют длину от 12 до 20 элементов.

## Методика тестирования

Машина: Lenovo XiaoXin X16 Pro (2024)

CPU: AMD Ryzen 7 8845H w/ Radeon 780M Graphics 3.80 GHz (8 cores, 16 threads)

Компилятор: g++ 13.3.0

OS: Linux Mint 22.1 x86_64

### Тестовые файлы

Указанные в сценарии использования файлы 1 и 2 будут сгенерированы из [полного собрания сочинений Шекспира](https://www.gutenberg.org/cache/epub/100/pg100.txt). [Файл](shakespeare.txt)

1.`testString.txt`: текст разделяется на слова, всё остальное убирается. Слова расположены по одному на строке. Всего примерно 25 тысяч уникальных слов.

2.`testRequests.txt`: набор из 10 миллионов слов (порядка 50МБ), 90% взяты из `testString.txt`, остальные сгенерированы рандомно с длиной от 3 до 14 символов.

Файл 2 обрабатывается `TEST_LOOPS` раз, по умолчанию 10.

Эти файлы генерируются при помощи команды `make test_file`. Можно поменять количество тестов при помощи `TESTS`(10 миллионов по умолчанию) и часть слов, взятых из файла 1 - `FOUND_PERCENT` (0.9 по умолчанию).

### Измерение времени

Для измерения времени использовались ~~14 индусов с секундомерами~~ `clock_gettime` в режиме `CLOCK_PROCESS_CPUTIME_ID` и `_rdtsc`. `_rdtsc` возвращает текущее количество тактов процессора, обладает большей точностью и меньшими накладными расходами, но поскольку время теста порядка 5-10 секунд, особо смысла в ней нет: гораздо большую погрешность вносит операционная система. Тем не менее его полезно использовать для оценки количества тактов, которые тратятся на один вызов.

Я не делал сравнения `_rdtsc` и `clock_gettime`, выводы были взяты из [статьи](https://habr.com/ru/articles/818965/) на `habr.com`.

Поскольку оптимизируется функция поиска, то наибольший интерес представляет время, проведенное в цикле подсчёта слов из файла 2. Время, затраченное на подготовку данных и загрузку слов из файла 1 в таблицу, не учитывается, так как это уже совсем другая задача.

### О погрешностях

Для оценки погрешности будем запускать тест 6 раз подряд.

Первый результат отбрасывается, т.к. на него с большей вероятностью влияло предыдущее состояние процессора и частота процессора могла не успеть стабилизироваться. От остальных пяти берётся среднее, в качестве погрешности считается среднеквадратичное отклонение:

```math
    \sigma_t = \sqrt{\frac{N}{N-1}} * \sqrt{\overline{t^2} - \overline{t}^2 }
```

(первый множитель - поправка, связанная с малым количеством измерений)

### Запуск теста

`make run`.

Программа пересобирается в релизную версию и запускается на 1 ядре суммарно 6 раз при помощи команды `taskset 0x1`.

Во время тестов все программы закрыты, кроме текстового редактора VSCode.

### Троттлинг

Его нет. Тест достаточно короткий (около 10 секунд), поэтому процессор не успевает нагреться выше 60 градусов. (температура измерялась при помощи утилиты `psensor`)

### Важно: Load factor

Load factor - среднее количество элементов в бакете таблицы. Оптимальным значением является 1.5-2 для таблиц на основе списков и 0.75 для хеш-таблиц на основе открытой адресации (в java 0.75), но в учебных целях таблица строится с заведомо большим коэффициентом "заполненности": 15-17. Это сделано для того, чтобы было проще увидеть части, которые занимают много времени при исполнении. В конце будет проведено сравнение с правильной "настройкой" хеш-таблицы.

## Ход работы: оптимизации

Структура первой версии:

+ Память для ключей и значений выделяется при помощи `calloc` (простая наивная реализация)
+ В бакетах элементы хранятся в виде списка (**не массив**), ноды выделяются при помощи `calloc`
+ О длинах строк ничего не известно

### Тесты первой версии

(Odefault - компиляция без ключей оптимизации)

| Версия   | Время, с       | Время одного запроса, тактов | Относительное улучшение |
|-------   |----            |-----                         |---------                |
| Odefault | 16.7  +- 0.1   | 634 +- 4                     | 1  |
| -O3      | 14.9  +- 0.1   | 566 +- 4                     | 1.12 +- 0.02 |

Для профилирования программы будем использовать утилиту `perf` и программу `hotspot` для анализа полученного профиля.

Иногда будут встречаться т.н. `flamegraph`ы - визуализация стека вызовов, отражающая время исполнения каждой функции.

Для запуска профилирования есть команда `make perfTest` - она компилирует релизную версию с флагом `-fno-omit-frame-pointer`, который делает обязательным сохранение rbp в функциях (без этого perf может неправильно интерпретировать stack trace и пропускать названия функций). 

Затем запускает профилирование c флагами `-g` (записать трейс стека) и `--call-graph dwarf`. Частота выборок по умолчанию 10000 Гц, но её можно поменять при помощи опции `FREQ`. **Примечание**: реальная частота снэпшотов perf может отличаться.

#### Профиль 1

При помощи `hotspot` рассмотрим наиболее горячие функции.

![no_opt](docs/hotspot_0.png)
(реальная частота 7.585KHz, примерно такие же частоты будут и на других тестах)

Отсортируем их по собственному времени. Видно, что наиболее ресурсоёмкой оказалась функция сравнения строк, а точнее `__strcmp_evex` - уже оптимизированная под AVX512 функция сравнения строк. Следующие кандидаты - функция поиска в списке и подсчёт хеша.

### Оптимизация strcmp

Как мы выяснили раньше, первым кандидатом на оптимизацию является `strcmp`. Несмотря на то, что библиотечная версия уже оптимизирована с применением SIMD, она ничего не знает о выравнивании и длине строк. Поэтому можно хранить ключи в таблице с выравниванием `KEY_ALIGNMENT`, и, возможно, длину ключей. Перейдём непосредственно к реализации.

+ `aligned_alloc` вместо `calloc` создаст необходимое выравнивание для строк, чтобы их можно было быстро загрузить в SIMD регистр.
+ Байты после конца строки нулевые до конца выравненного блока. Это позволит не беспокоиться о том, что в SIMD регистр попадёт часть другой строки или вообще чужая память.
+ Если известна длина строки, то логично сначала сравнить её. Несмотря на то, что это алгоритмическая оптимизация, не добавлять её довольно глупо. Она может быть включена при помощи `#define CMP_LEN_FIRST`.
+ Оптимизированный `fastStrcmp`:

    ```c
    typedef __m128i MMi_t;
    #define _MM_LOAD(ptr) _mm_load_si128(ptr)
    #define _MM_CMP_MOVEMASK(a, b) _mm_movemask_epi8(_mm_cmpeq_epi8(a, b))
    static const uint32_t _MM_MASK_CONSTANT = 0xFFFF;

    static int fastStrcmp(MMi_t a, MMi_t *bptr) {
        MMi_t b = _MM_LOAD(bptr);
        //k-th bit of cmpMask = (a[k] == b[k])
        uint32_t cmpMask = (uint32_t) _MM_CMP_MOVEMASK(a, b); 
        //_MM_MASK_CONSTANT is 0xFFFF for SSE and 0xFFFFFFFFF for AVX2
        return (int) (cmpMask ^ _MM_MASK_CONSTANT); 
    }
    ```

    **Примечание**: работа с интринсиками была сделана с помощью макросов, чтобы можно было просто сравнить скорость выполнения с разными наборами `SIMD` команд (`xmm/ymm/zmm`). Тесты показали, что работа с памятью тем быстрее, чем меньше блок данных, к которому нужно получить доступ. В итоге были выбраны инструкции для работы с `xmm` регистрами, так как лишь 6 строк из тестовых данных были длиннее 16 символов, и для них будет быстрее использовать обычный `strcmp`.

    В SSE4.2 есть специализированные инструкции для сравнения строк, но у них [задержка](https://www.laruence.com/sse/) минимум в 10 тактов, в то время как комбинация `cmpeq` и `movemask` требует суммарно 3 такта.

    `fastStrcmp` предполагает, что ключ был загружен в SIMD регистр. Посмотрим, как это делается:

    ```c
    /// Part of the bucketSearch function
    keyLen = strlen(key);

    if (keyLen >= SMALL_STR_LEN) {
        // Key doesn't fit in SIMD register
        while (node) {
            if (CMP_LEN_OPT(node->len == keyLen &&) strcmp(node->key, key) == 0 )
                return node;

            node = node->next;
        }

    } else {
        // Creating local aligned array of chars for key
        alignas(KEY_ALIGNMENT) char keyCopy[SMALL_STR_LEN] = "";
        // Copying key to it
        memcpy(keyCopy, key, keyLen+1);
        // Loading key to SIMD register
        MMi_t searchKey = _MM_LOAD((MMi_t *) keyCopy);

        while (node) {
            //! Alignment of node->key is guaranteed by aligned_calloc with KEY_ALIGNMENT
            if (CMP_LEN_OPT(node->len == keyLen &&) fastStrcmp(searchKey, (MMi_t *) node->key) == 0)
                return node;

            node = node->next;

        }
    }
    ```

    `CMP_LEN_OPT(...)` раскрывается в свои аргументы, если есть `#define CMP_LEN_FIRST`. Так можно отключить эту оптимизацию и убрать одно из полей в структуре ноды.

    Использование `memcpy`, даже несмотря на то, что компилятор инлайнит эту функцию, может быть довольно медленным. Возможно лучшим решением будет невыровненная загрузка 16 байт в `xmm` регистр и маскирование лишних байт после конца строки. Проверим эту теорию позже.

#### Результаты тестирования


| `FAST_STRCMP` | `CMP_LEN_FIRST` | Время, с | Тактов | Относительное улучшение |
|---------------|-----------------|----------|--------|-------------------------|
| -O3           | (пред. версия)  | 14.9  +- 0.1  | 566 +- 4 | 1                |
| Да            | Нет             | 12.40 +- 0.04 | 470 +- 2 | 1.20 +- 0.01     |
| Нет           | Да              | 13.18 +- 0.06 | 500 +- 2 | 1.13 +- 0.01     |
| Да            | Да              | 12.43 +- 0.06 | 471 +- 2 | 1.20 +- 0.01     |

Время работы уменьшилось в 1.2 раза. При этом предварительное сравнение длин строк не улучшило результат.

Проведём профилирование, отключив предварительное сравнение длин строк:

![strcmp_opt](docs/hotspot_1.png)

Теперь сравнение строк суммарно занимает порядка 35% - заметное улучшение.

Попробуем описанный ранее альтернативный метод загрузки ключа в регистр:

``` c
// 16 0xFF and 16 0x00
const uint8_t mask[32] = 
{255, 255, 255, 255, 255, 255, 255, 255, 
    255, 255, 255, 255, 255, 255, 255, 255};

MMi_t searchKey = _mm_loadu_si128((const __m128i_u *) key);
MMi_t maskReg   = _mm_loadu_si128((const __m128i_u *) (mask + (16 - keyLen)) );
searchKey = _mm_and_si128(searchKey, maskReg);
```

Проведём тестирование:

| Версия | Время, с | Тактов | Относительное улучшение |
|---------------|-----------------|----------|-------|
| `FAST_STRCMP` | 12.43 +- 0.06 | 471 +- 2 | 1     |
| Загрузка маскированием | 12.45 +- 0.04 | 472   +- 1.3 | 0.998 +- 0.006 |

В пределах погрешности время работы не изменилось. Пока вернёмся к предыдущему подходу.

### Оптимизация `bucketSearch`

Из тестовых данных предыдущего раздела следует, что теперь нужно оптимизировать функцию `bucketSearch`, которая проводит поиск элемента по ключу в пределах одного бакета.

1. Компилятор инлайнит эту функцию
2. Самая горячая часть - непосредственно цикл

```c
    while (node) {
            //! Alignment of node->key is guaranteed by aligned_calloc with KEY_ALIGNMENT
            if (fastStrcmp(searchKey, (MMi_t *) node->key) == 0)
                return node;

            node = node->next;
    }
```

Это логично и подтверждается `perf`ом:

```
             ↓ jne       170  
  0,24  126:   vmovdqa   -0x40(%rbp),%xmm1
  0,23         test      %rbx,%rbx
             ↓ jne       14c  
             ↓ jmp       1f0  
               data16    cs nopw 0x0(%rax,%rax,1)
 11,86  140:   mov       (%rbx),%rbx
 11,72         test      %rbx,%rbx
  0,00       ↓ je        1f0  
 11,20  14c:   mov       0x10(%rbx),%rax
 11,69         vpcmpeqb  (%rax),%xmm1,%xmm0
 11,87         vpmovmskb %xmm0,%eax
 11,25         cmp       $0xffff,%eax
  0,00       ↑ jne       140  
 10,04       ↑ jmp       cc   
               data16    cs nopw 0x0(%rax,%rax,1)
               nop            
  0,04  170:   movzbl    (%rax,%rdx,1),%eax
  0,17         mov       %al,(%rdi,%rdx,1)
  0,05       ↑ jmp       126  
               nop            
```

Этот кусок кода занимает 80% времени в функции `hashTableGetBucketAndElement`, поэтому на него стоит обратить внимание в первую очередь.

Посмотрим на этот код в человеческом синтаксисе (Intel) при помощи [GODBOLT](https://godbolt.org/z/6PYzfqn9e):

![Disasm of bucketSearch function](docs/godbolt_bucketSearch.png)

Можно заметить, что компилятор сгенерировал отличный код. Добиться лучшей производительности в этом месте при помощи переписывания на ассемблере скорее всего не получится.

Прибегнем к архитектурным оптимизациям. В этом цикле часто происходит обращение к памяти, причём куски этой памяти могут лежать далеко не последовательно, т.к. они выделялись при помощи `calloc`. Чтобы улучшить локальность, можно

1. Переделать список элементов в бакете в массив
2. Хранить короткие ключи прямо в структуре в `__m128i`
3. Длинные ключи хранить в отдельном массиве
4. Добавить опцию хранения значения рядом с нодой
5. Возможно требовать от передаваемых для поиска ключей выравнивание и нули до конца выровненного блока

Поскольку удаление и вставка не являются основными в этой работе, потери от того, что эти операции происходят медленнее в массиве, чем в списке, незаметны. (Также стоит помнить, что в реальной таблице большинство бакетов будут иметь размер до 5 элементов (при заполненности 2) , поэтому накладные расходы не такие большие ).

Эти изменения доступны с помощью `#define HASH_TABLE_ARCH 2` - код в файле с первой версией будет удалён условной компиляцией.

#### Новая структура ноды

```c
typedef struct hashTableNode {
    union {
    __m128i keyMM;  ///< Key is stored in node when it doesn't exceed SMALL_STR_LEN
    char *keyPtr;   ///< Otherwise we use pointer to string stored somewhere else
    };
    void  *value;   ///< Pointer to data stored in element
    CMP_LEN_OPT(uint32_t len;)
} hashTableNode_t;
```

Короткие ключи хранятся прямо в структуре, для длинных память выделяется отдельно.

Из-за `__m128i` компилятор сделает выравнивание структуры на 16 байта, поэтому для значений (пункт 4) можно сделать аналогичное объединение - хранить короткие значения в структуре, а на длинные брать указатель.

#### Тест новой архитектуры хеш-таблицы

Результат тестирования для версии, в которой реализованы пункты 1-3:

| Версия | Время,с | Такты | Относительное ускорение |
|------|--------|--------|--------------------|
| FastStrcmp | 12.40 +- 0.04 | 470 +- 2  | 1            |  
| Arch 2     | 2.43 +- 0.01  | 92 +- 0.5 | 5.11 +- 0.05 |

Такой большой прирост заставляет задуматься о корректности работы программы, однако результаты (частоты слов в тексте) совпадают с предыдущей версией.

Посмотрим на аппаратные счётчики производительности, которые можно получить при помощи `perf stat`:

```
    Arch 2 version
     1 927 336 754      cache-references                                                      
        97 255 494      cache-misses                     #    5,05% of all cache refs         
    14 096 514 424      cycles                                                                
    21 523 886 400      instructions                     #    1,53  insn per cycle            
     4 475 085 513      branches                                                              
            79 594      faults                                                                
                 4      migrations                                                   

    FastStrcmp version
     3 033 857 010      cache-references                                                      
       640 835 978      cache-misses                     #   21,12% of all cache refs         
    62 833 324 538      cycles                                                                
    30 568 617 557      instructions                     #    0,49  insn per cycle            
     6 959 783 154      branches                                                              
            79 724      faults                                                                
                13      migrations                                        
```

Процент промахов кеша упал в 4 раза.

![Hottest functions in Arch2](docs/hotspot_2.png)

Теперь посмотрим, будут ли изменения, если добавить пункты 5(требование выравнивания для ключей)  и/или 4(хранение значения рядом с нодой) из предложенных ранее.

Выровненные ключи (5) позволяют загрузить их в SIMD регистр одной инструкцией, без маскирования.

| Версия | Время,с | Такты | Относительное ускорение |
|------|--------|--------|--------------------|
| Arch 2     | 2.43 +- 0.01  | 92 +- 0.5 | 1|
| Arch 2 + aligned keys |  2.38 +- 0.01 | 90.1 +- 0.4 | 1.02 +-0.01 |

Ускорение практически в пределах погрешности. Это связано с тем, что современные процессоры обрабатывают доступ к невыровненной памяти фактически без падения производительности. На данном этапе выгода, получаемая от этого требования к пользовательским данным, слишком мала, чтобы эта оптимизация имела смысл.

**О выравнивании пользовательских ключей**: по умолчанию текст разделяется на слова, которые хранятся в выровненных блоках памяти. Это можно отключить, убрав `#define ALIGN_USER_KEYS` в [perfTester.h](include/perfTester.h). После замеров было установлено, что разница производительности у этих двух методов в пределах погрешности.

TODO: сделать архитектурную оптимизацию 4.

### Оптимизация хеш-функции CRC32

![Hottest functions in Arch2](docs/hotspot_2.png)

Следующий кандидат на оптимизацию - функция хеширования. CRC32 настолько популярен, что проектировщики процессоров добавили специализированные инструкции для аппаратного ускорения подсчёта хеша этим алгоритмом.

**Примечание**: CRC32 может строиться на разных полиномах. Выбор полинома не влияет на производительность, но может немного влиять на равномерность распределения хеш-функции. Версия алгоритма, которую я использую по умолчанию, построена на полиноме `0xEDB88320`, в то время как соответствующая инструкция x86_64 использует полином `0x11EDC6F41`.

```asm
;========================================================
; Crc32 hashing algorithm for C strings
; Args:
;   rdi - memory address
; Ret:
;   rax - crc32 hash
;========================================================
fastCrc32u:
    xor  rax, rax
    dec  rax        ; rax = all ones
    jmp  .loop_cmp
    .hash_loop:
        crc32 rax, sil
        .loop_cmp:
        mov   sil, BYTE [rdi]
        inc   rdi
        test  sil, sil
        jnz   .hash_loop

    ret
```

| Время, с | Такты |
|----------|-------|
| 2.23 +- 0.01 | 84.7 +- 0.4 |

**Примечание**: на моих тестовых даннах дисперсия распределения элементов по бакетам с этой хеш-функцией составила 3.96, в то время как на предыдущей была 4.03

Если воспользоваться тем, что ключи выравнены, то получим функцию, которая считает хеш 16 байт всего за 3 инструкции:

```c
// Calculate crc32 hash of 16 bytes of data
hash_t fastCrc32_16(const void *data) {
    hash_t crc = 0xFFFFFFFF;
    asm("crc32q  (%[ptr]), %[crc]\n\t"
        "crc32q 8(%[ptr]), %[crc]\n" 
      : [crc] "+r" (crc)
      : [ptr] "r" (data));
    return crc;
}
```

Результаты выполнения с ней:

|Hash| Время, с | Такты | Относительное улучшение |
|----|----------|-------|-------------------------|
|fastCrc32u | 2.23 +- 0.01 | 84.7 +- 0.4 | 1 |
|fastCrc32_16| 2.196 +- 0.006 | 83.3 +- 0.2 | 1.017 +- 0.005 |

Улучшение менее чем на 2%.

### Тест с правильным load factor

| Версия | Время, с | Такты | Относительное улучшение |
|----|----------|-------|-------------------------|
| fastCrc32_16 | 2.196 +- 0.006 | 83.3 +- 0.2 | 1 |
| LoadFactor=1.23 | 1.77 +- 0.03 | 67 +- 1 | 1.24 |

## Вывод

Приведём профиль последней версии:

![Профиль с оптимизированной функцией хеширования](docs/hotspot_3.png)

Функция хеширования теперь занимает всего 2% от общего времени.

Следующим шагом оптимизаций может быть оптимизирование strlen: длины всех строк известны на этапе подготовке данных и их можно хранить.

|Оптимизация| Время, с | Такты | Относительное улучшение |
|----|----------|-------|-------------------------|
| Odefault | 16.7  +- 0.1   | 634 +- 4   | 1 |
| -O3      | 14.9  +- 0.1   | 566 +-4    |1.12 |
| FastStrcmp | 12.40 +- 0.04 | 470 +- 2  | 1.35          |  
| Arch 2     | 2.43 +- 0.01  | 92 +- 0.5 | 6.89 |
| Arch 2 + aligned keys |  2.38 +- 0.01 | 90.1 +- 0.4 | 7.04 |
|fastCrc32u | 2.23 +- 0.01 | 84.7 +- 0.4 | 7.48 |
|fastCrc32_16| 2.196 +- 0.006 | 83.3 +- 0.2 | 7.61 |
| LoadFactor=1.23 | 1.77 +- 0.03 | 67 +- 1 | 9.46 |

Наибольший прирост производительности был получен за счёт выбора правильного способа хранения ключей в таблице, что позволило гораздо эффективнее использовать кеш.

Ещё один важный вывод: для обычного использования хэш таблицы практически не смысла усложнять пользовательскую логику, требуя выравнивания от ключей. Современные процессоры очень хорошо справляются с доступом к невыровненной памяти.

**Примечание**: после последней оптимизации (fastCrc32_16) время подготовки файлов и загрузки строк в таблицу занимает примерно 10% от общего времени, поэтому предположение о том, что нужно оптимизировать поиск - оправдано.
